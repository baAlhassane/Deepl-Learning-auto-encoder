{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.ToTensor()\n",
    "mnist_data=datasets.MNIST(root=\"./data\",train=True,download=True,transform=transform)\n",
    "data_loader=torch.utils.data.DataLoader(dataset=mnist_data,batch_size=64,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inspecte the firt batch\n",
    "dataiter=iter(data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 784])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images, label=dataiter.next()\n",
    "images,label\n",
    "images=images.reshape(-1,28*28)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.), tensor(1.))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valmin=torch.min(images)\n",
    "valmax=torch.max(images)\n",
    "valmin,valmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_lenear(nn.Module):\n",
    "    def __init__(self):\n",
    "        #N,784 N=batch_size\n",
    "        super().__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Linear(28*28,128),#reduce size :N,784->N,128\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12,3),#size here is N by 3\n",
    "            #here we don't need the activation fonction\n",
    "        )\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.Linear(3,12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64,128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,28*28),\n",
    "            nn.Sigmoid()#because value are beetween 0 and 1\n",
    "            #if valuer min and max are in range [-1,+1] we will chose thn\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        encoded=self.encoder(x)\n",
    "        decoded=self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the best way to struct a  with autoencoder is to use sequencile  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model \n",
    "model=Autoencoder_lenear()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
    "#x=torch.rand(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the training \n",
    "# num_epochs=10\n",
    "# outputs=[]\n",
    "# for epoch in range(num_epochs):\n",
    "#     for (img,_) in data_loader:\n",
    "#         img=img.reshape(-1,28*28)\n",
    "#         recon=model(img)\n",
    "#         loss=criterion(recon,img)#loss entre image autoencoder et image original\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch:{epoch+1},Loss:{loss.item():.4f}' )\n",
    "#     outputs.append((epoch,img,recon))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(0,num_epochs,4):\n",
    "#     plt.figure(figsize=(9,2))\n",
    "#     #plt.gray()\n",
    "#     imgs=outputs[k][1].detach().numpy()\n",
    "#     recon=outputs[k][2].detach().numpy()\n",
    "#     for i,item in enumerate(imgs):\n",
    "#         if i>=9:break\n",
    "#         plt.subplot(2,9,i+1)\n",
    "#         item=item.reshape(-1,28,28)\n",
    "#         plt.imshow(item[0])\n",
    "#     for i,item in enumerate(recon): \n",
    "#         if i>=9:break\n",
    "#         plt.subplot(2,9,9+i+1)#row length+i+1\n",
    "#         item=item.reshape(-1,28,28)\n",
    "#         plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder_CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        #N,1,28,28 N=batch_size\n",
    "        super().__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(1,16,3 ,stride=2,padding=1),# N,covolutional layer\n",
    "            #first input size=1, after 16, after reduce the size in half 14,14\n",
    "            #the output is 16. N,16,14,14\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16,32,3 ,stride=2,padding=1),\n",
    "            #here we increase the the imput by x2 #N,32,7,7\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32,64,7)#N,64,1,1\n",
    "            #here we don't need the activation fonction\n",
    "        )\n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.ConvTranspose2d(64,32,7),#N,32,7,7\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32,16,3, stride=2,padding=1,output_padding=1),#N,16,14,14\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(16,1,3, stride=2,padding=1,output_padding=1),#N,1,28,28\n",
    "            nn.Sigmoid()#because value are beetween 0 and 1\n",
    "            #if valuer min and max are in range [-1,+1] we will chose thn\n",
    "            \n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        encoded=self.encoder(x)\n",
    "        decoded=self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model \n",
    "model=Autoencoder_CNN()\n",
    "criterion=nn.MSELoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
    "x=torch.rand(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the training \n",
    "# num_epochs=10\n",
    "# outputs=[]\n",
    "# for epoch in range(num_epochs):\n",
    "#     for (img,_) in data_loader:\n",
    "#         #img=img.reshape(-1,28*28)\n",
    "#         recon=model(img)\n",
    "#         loss=criterion(recon,img)#loss entre image autoencoder et image original\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#     print(f'Epoch:{epoch+1},Loss:{loss.item():.4f}' )\n",
    "#     outputs.append((epoch,img,recon))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for k in range(0,num_epochs,4):\n",
    "#     plt.figure(figsize=(9,2))\n",
    "#     #plt.gray()\n",
    "#     imgs=outputs[k][1].detach().numpy()\n",
    "#     recon=outputs[k][2].detach().numpy()\n",
    "#     for i,item in enumerate(imgs):\n",
    "#         if i>=9:break\n",
    "#         plt.subplot(2,9,i+1)\n",
    "#         #item=item.reshape(-1,28,28)\n",
    "#         plt.imshow(item[0])\n",
    "#     for i,item in enumerate(recon): \n",
    "#         if i>=9:break\n",
    "#         plt.subplot(2,9,9+i+1)#row length+i+1\n",
    "#         #item=item.reshape(-1,28,28)\n",
    "#         plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def ___init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder=nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1,out_channels=4,kernel_size=5),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=4),\n",
    "            \n",
    "            nn.Conv2d(in_channels=4,out_channels=8,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            \n",
    "            nn.Conv2d(in_channels=8,out_channels=8,kernel_size=7),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            \n",
    "            nn.Conv2d(in_channels=8,out_channels=16,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16,out_channels=16,kernel_size=4,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            \n",
    "            nn.Conv2d(in_channels=16,out_channels=32,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=32)\n",
    "        )\n",
    "        self.encoder_mu=nn.Linear(in_features=32,out_features=32)#voir video 1h11min\n",
    "        self.encoder_sigma=nn.Linear(in_features=32,out_features=32)\n",
    "        \n",
    "        self.decoder=nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels=32,out_channels=16,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=16,our_channels=16,kernel_size=4,padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=16),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=16,out_channels=8,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=8,out_channels=8,kernel_size=7),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=8),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=8,out_channels=4,kernel_size=4,padding=1,stride=2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm2d(num_features=4),\n",
    "            \n",
    "            nn.ConvTranspose2d(in_channels=4,out_channels=1,kernel_size=5),\n",
    "            nn.Sigmoid()\n",
    "            \n",
    "        )\n",
    "    def forward(self,x):\n",
    "        out=self.encoder(x)\n",
    "        out_flat=out.view(x.size(0),-1)\n",
    "        z_sigma=self.encoder_sigma.forward(out_flat)\n",
    "        z_mu=self.encoder_mu.forward(out_flat)\n",
    "        eps=torch.normal(mean=0.0,std=1.0,size=z_mu.size()).to(DEVICE)\n",
    "        z=z_mu+z_sigma*eps\n",
    "        z_2d=z.view(x.size(0),-1,1,1)\n",
    "        y_prim=self.decoder(z_2d)\n",
    "        return y_prim,z,z_sigma,z_mu\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the model \n",
    "# model=Autoencoder_CNN()\n",
    "# criterion=nn.MSELoss()\n",
    "# optimizer=torch.optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-5)\n",
    "# x=torch.rand(784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VAE()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_model=VAE()\n",
    "#parameters = vae_model.parameters()\n",
    "#vae_optimizer=torch.optim.Adam(parameters,lr=1e-3,weight_decay=1e-5)\n",
    "#vae_model=vae_model.to(DEVICE)\n",
    "#x=torch.rand(784)\n",
    "vae_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
